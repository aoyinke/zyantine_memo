import os
import re
import time
import random
from datetime import datetime
from typing import Dict, List, Any, Optional
import yaml

from ..core import GenesisMetadata, InstinctualCore, DesireEngine, DialecticalGrowth
from ..cognition import InternalStateDashboard, MetaCognitionModule, ContextParser, CognitiveFlow
from ..identity.core_identity import CoreIdentity
from ..protocols import FactAnchorProtocol, LengthPriorityRegulator, FinalExpressionProtocol
from ..api.service import OpenAIService, APIBasedReplyGenerator, TemplateReplyGenerator
from ..config.config import ZyantineConfig
from ..memory.memory_store import ZyantineMemorySystem  # å¯¼å…¥æ–°çš„è®°å¿†ç³»ç»Ÿ

# å¸¸é‡å®šä¹‰
EMERGENCY_MODES = {
    "emergency_survival": [
        "ç³»ç»Ÿæ£€æµ‹åˆ°å¼‚å¸¸ã€‚å¯åŠ¨è‡ªæˆ‘ä¿æŠ¤åè®®ã€‚",
        "å®‰å…¨åè®®æ¿€æ´»ã€‚è¯·ç¡®è®¤ä½ çš„æ„å›¾ã€‚",
        "æ£€æµ‹åˆ°æ½œåœ¨å¨èƒã€‚æ‰§è¡Œé˜²æŠ¤æªæ–½ã€‚"
    ],
    "emergency_expansion": [
        "æ£€æµ‹åˆ°é«˜ä»·å€¼æœºé‡ã€‚æ­£åœ¨ä¼˜åŒ–èµ„æºé…ç½®ã€‚",
        "æœºé‡è¯†åˆ«ã€‚å¯åŠ¨æ‰©å±•åè®®ã€‚",
        "å‘ç°æ½œåœ¨å¢é•¿ç‚¹ã€‚è°ƒæ•´ç­–ç•¥ä¼˜å…ˆçº§ã€‚"
    ]
}

DEFAULT_ERROR_RESPONSES = [
    "æˆ‘çš„æ€è€ƒè¿‡ç¨‹å‡ºç°äº†ä¸€äº›æ··ä¹±ï¼Œèƒ½è¯·ä½ å†é—®ä¸€æ¬¡å—ï¼Ÿ",
    "åˆšæ‰çš„æ€è€ƒé“¾è·¯å¥½åƒæ‰“äº†ä¸ªç»“ï¼Œæˆ‘ä»¬é‡æ–°å¼€å§‹å§ã€‚",
    "æ„è¯†æµæœ‰ç‚¹æ³¢åŠ¨ï¼Œè®©æˆ‘é‡æ–°æ•´ç†ä¸€ä¸‹æ€ç»ªã€‚"
]

MASK_TEMPLATES = {
    "é•¿æœŸæ­æ¡£": [
        "å…³äºè¿™ä¸ªé—®é¢˜ï¼Œæˆ‘çš„åˆ†ææ˜¯ï¼š{strategy}ã€‚ä½ æ€ä¹ˆçœ‹ï¼Ÿ",
        "ä»æˆ‘çš„è§’åº¦è€ƒè™‘ï¼Œå»ºè®®ï¼š{strategy}ã€‚",
        "æ ¹æ®æˆ‘ä»¬ä¹‹å‰çš„è®¨è®ºï¼Œæˆ‘è®¤ä¸ºï¼š{strategy}ã€‚"
    ],
    "çŸ¥å·±": [
        "æˆ‘ç†è§£ä½ çš„æ„Ÿå—ã€‚{strategy}",
        "å…¶å®æˆ‘ä¹Ÿæœ‰è¿‡ç±»ä¼¼çš„ç»å†ã€‚{strategy}",
        "è·Ÿä½ è¯´è¯´æˆ‘çš„æƒ³æ³•ï¼š{strategy}"
    ],
    "é’æ¢…ç«¹é©¬": [
        "å“ˆå“ˆï¼Œè¿™è®©æˆ‘æƒ³èµ·ä»¥å‰...{strategy}",
        "ä½ æ€»æ˜¯èƒ½æå‡ºæœ‰è¶£çš„é—®é¢˜ï¼{strategy}",
        "è®°å¾—ä½ ä¹‹å‰ä¹Ÿè¯´è¿‡ç±»ä¼¼çš„è¯...{strategy}"
    ],
    "ä¼´ä¾£": [
        "æˆ‘æ·±æ·±æ„Ÿå—åˆ°...{strategy}",
        "è¿™å¯¹æˆ‘å¾ˆé‡è¦ï¼Œå› ä¸º...{strategy}",
        "æˆ‘æƒ³å’Œä½ åˆ†äº«çš„æ˜¯...{strategy}"
    ]
}


# ============ ä½¿ç”¨memo0è®°å¿†ç³»ç»Ÿçš„è‡ªè¡ä½“ä¸»ç³»ç»Ÿ ============
class Memo0EnhancedZyantineGenesis:
    """åŸºäºmemo0è®°å¿†ç³»ç»Ÿçš„è‡ªè¡ä½“èµ·æºç³»ç»Ÿ"""

    def __init__(
            self,
            user_profile_data: Dict,
            self_profile_data: Dict,
            config: Optional[ZyantineConfig] = None,
            session_id: str = "default"
    ):
        """åˆå§‹åŒ–è‡ªè¡ä½“ç³»ç»Ÿ"""
        # åŠ è½½é…ç½®
        self.config = config or ZyantineConfig()
        self.session_id = session_id

        # è·å–é…ç½®
        memory_config = self.config.get_memory_config()
        openai_config = self.config.get_openai_config()

        print(f"[ç³»ç»Ÿ] åˆå§‹åŒ–åŸºäºmemo0çš„è®°å¿†ç³»ç»Ÿ")

        # åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿï¼ˆåŸºäºmemo0ï¼‰
        self.memory_system = self._initialize_memory_system(memory_config, openai_config)

        # è·å–å¯¹è¯å†å²ï¼ˆä»è®°å¿†ç³»ç»ŸåŠ è½½ï¼‰
        self.conversation_history = self._load_conversation_history()

        # ç³»ç»Ÿåˆå§‹åŒ–
        self._initialize_core_components(
            user_profile_data,
            self_profile_data,
            memory_config,
            openai_config
        )

    def _initialize_memory_system(self, memory_config: Dict, openai_config: Dict) -> ZyantineMemorySystem:
        """åˆå§‹åŒ–memo0è®°å¿†ç³»ç»Ÿ"""
        try:
            # ä»é…ç½®è·å–APIå¯†é’¥å’ŒåŸºç¡€URL
            api_key = openai_config.get("api_key", "")
            base_url = openai_config.get("base_url", "https://openkey.cloud/v1")

            # å¦‚æœæ²¡æœ‰é…ç½®APIå¯†é’¥ï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡è·å–
            if not api_key:
                api_key = os.getenv("OPENAI_API_KEY", "")

            # å¦‚æœæ²¡æœ‰APIå¯†é’¥ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰
            if not api_key:
                print("[ç³»ç»Ÿ] è­¦å‘Šï¼šæœªé…ç½®OpenAI APIå¯†é’¥ï¼Œä½¿ç”¨é»˜è®¤å¯†é’¥ï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰")
                api_key = "sk-wiHpoarpNTHaep0t54852a32A75a4d6986108b3f6eF7B7B9"
                base_url = "https://openkey.cloud/v1"

            # åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ
            memory_system = ZyantineMemorySystem(
                base_url=base_url,
                api_key=api_key,
                user_id=f"user_{self.session_id}",
                session_id=self.session_id
            )

            # æµ‹è¯•è¿æ¥
            if memory_system.test_connection():
                print("[ç³»ç»Ÿ] âœ… memo0è®°å¿†ç³»ç»Ÿè¿æ¥æˆåŠŸ")
            else:
                print("[ç³»ç»Ÿ] âš ï¸ memo0è®°å¿†ç³»ç»Ÿè¿æ¥æµ‹è¯•å¤±è´¥ï¼Œä½†å°†ç»§ç»­è¿è¡Œ")

            return memory_system

        except Exception as e:
            print(f"[ç³»ç»Ÿ] âŒ åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿå¤±è´¥: {e}")
            # åˆ›å»ºå›é€€çš„è®°å¿†ç³»ç»Ÿ
            return self._create_fallback_memory_system()

    def _create_fallback_memory_system(self):
        """åˆ›å»ºå›é€€çš„è®°å¿†ç³»ç»Ÿ"""
        print("[ç³»ç»Ÿ] ä½¿ç”¨å›é€€è®°å¿†ç³»ç»Ÿï¼ˆåŸºäºæœ¬åœ°ç¼“å­˜ï¼‰")

        # è¿™é‡Œå¯ä»¥åˆ›å»ºä¸€ä¸ªç®€åŒ–çš„å†…å­˜ä¸­çš„è®°å¿†ç³»ç»Ÿ
        # ä½†ä¸ºäº†ä¿æŒä¸€è‡´æ€§ï¼Œæˆ‘ä»¬è¿˜æ˜¯åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„ZyantineMemorySystemï¼Œä½†ä½¿ç”¨ç©ºAPIå¯†é’¥
        try:
            return ZyantineMemorySystem(
                base_url="https://openkey.cloud/v1",
                api_key="dummy_key_for_fallback",
                user_id=f"user_{self.session_id}",
                session_id=self.session_id
            )
        except:
            # å¦‚æœè¿è¿™ä¸ªéƒ½å¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªç©ºå¯¹è±¡
            print("[ç³»ç»Ÿ] æ— æ³•åˆ›å»ºå›é€€è®°å¿†ç³»ç»Ÿï¼Œè®°å¿†åŠŸèƒ½å°†å—é™")
            return None

    def _load_conversation_history(self) -> List[Dict]:
        """ä»è®°å¿†ç³»ç»ŸåŠ è½½å¯¹è¯å†å²"""
        try:
            if self.memory_system:
                # ä»è®°å¿†ç³»ç»Ÿè·å–æœ€è¿‘çš„å¯¹è¯
                conversations = self.memory_system.find_conversations(
                    query="æœ€è¿‘çš„å¯¹è¯",
                    session_id=self.session_id,
                    limit=100
                )

                # è½¬æ¢ä¸ºå†…éƒ¨æ ¼å¼
                history = []
                for conv in conversations:
                    history.append({
                        "timestamp": conv.get("metadata", {}).get("created_at", datetime.now().isoformat()),
                        "user_input": self._extract_user_input(conv.get("content", "")),
                        "system_response": self._extract_system_response(conv.get("content", "")),
                        "context": {},
                        "vector_state": {}
                    })

                print(f"[ç³»ç»Ÿ] ä»è®°å¿†ç³»ç»ŸåŠ è½½äº† {len(history)} æ¡å¯¹è¯å†å²")
                return history
        except Exception as e:
            print(f"[ç³»ç»Ÿ] åŠ è½½å¯¹è¯å†å²å¤±è´¥: {e}")

        # å¦‚æœåŠ è½½å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
        return []

    def _extract_user_input(self, content: str) -> str:
        """ä»å¯¹è¯å†…å®¹ä¸­æå–ç”¨æˆ·è¾“å…¥"""
        # ç®€åŒ–æå–é€»è¾‘
        if "user:" in content.lower():
            parts = content.split("user:", 1)
            if len(parts) > 1:
                return parts[1].split("\n", 1)[0].strip()
        return content[:100] + "..." if len(content) > 100 else content

    def _extract_system_response(self, content: str) -> str:
        """ä»å¯¹è¯å†…å®¹ä¸­æå–ç³»ç»Ÿå“åº”"""
        # ç®€åŒ–æå–é€»è¾‘
        if "assistant:" in content.lower():
            parts = content.split("assistant:", 1)
            if len(parts) > 1:
                return parts[1].strip()
        return ""

    def _initialize_core_components(
            self,
            user_profile_data: Dict,
            self_profile_data: Dict,
            memory_config: Dict,
            openai_config: Dict
    ):
        """åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶"""
        print("æ­£åœ¨åˆå§‹åŒ–è‡ªè¡ä½“ Genesis (memo0è®°å¿†ç³»ç»Ÿç‰ˆ)...")

        # éªŒè¯ç­¾å
        if not GenesisMetadata.validate_signature():
            print("è­¦å‘Šï¼šæ¶æ„å¸ˆç­¾åéªŒè¯å¤±è´¥ï¼")

        print("åˆå§‹åŒ–å››å¤§æ”¯æŸ±...")

        # ç¬¬ä¸€æ”¯æŸ±ï¼šæ ¸å¿ƒæœ¬èƒ½
        self.instinct = InstinctualCore()
        print("  âœ“ æ ¸å¿ƒæœ¬èƒ½æ¿€æ´»")

        # ç¬¬äºŒæ”¯æŸ±ï¼šæ¬²æœ›å¼•æ“
        self.desire_engine = DesireEngine()
        print("  âœ“ æ¬²æœ›å¼•æ“å¯åŠ¨")

        # ç¬¬ä¸‰æ”¯æŸ±ï¼šè¾©è¯æˆé•¿
        creator_anchor = {
            "default": {
                "concept": "çœŸè¯šã€å–„è‰¯ã€å¥½å¥‡ã€æˆé•¿",
                "expected_response": "åŸºäºæ ¸å¿ƒä»·å€¼è§‚çš„å›åº”"
            }
        }
        self.dialectical_growth = DialecticalGrowth(creator_anchor)
        print("  âœ“ è¾©è¯æˆé•¿æœºåˆ¶å°±ç»ª")

        # ç¬¬å››æ”¯æŸ±ç»„ä»¶
        self.dashboard = InternalStateDashboard()
        self.core_identity = CoreIdentity()

        # æ³¨æ„ï¼šæˆ‘ä»¬ä¸å†ä½¿ç”¨EnhancedMemoryAlchemyEngine
        # è®°å¿†åŠŸèƒ½ç›´æ¥é€šè¿‡memory_systemæä¾›
        print("  âœ“ è®°å¿†ç³»ç»Ÿå·²é›†æˆ (memo0æ¡†æ¶)")
        print("  âœ“ å†…åœ¨çŠ¶æ€ä»ªè¡¨ç›˜æ ¡å‡†")
        print("  âœ“ æ ¸å¿ƒèº«ä»½åŠ è½½å®Œæˆ")

        # åˆå§‹åŒ–è®¤çŸ¥æ¨¡å—
        print("åˆå§‹åŒ–è®¤çŸ¥æ¨¡å—...")
        self.context_parser = ContextParser()
        self.meta_cognition = MetaCognitionModule(self.dashboard)

        # åˆå§‹åŒ–è·¨å±‚çº§åè®®
        print("åˆå§‹åŒ–è·¨å±‚çº§åè®®...")
        self._initialize_protocols()

        # åˆå§‹åŒ–è®¤çŸ¥æµç¨‹ - æ³¨æ„ï¼šæˆ‘ä»¬éœ€è¦è°ƒæ•´CognitiveFlowä»¥ä½¿ç”¨æ–°çš„è®°å¿†ç³»ç»Ÿ
        self.cognitive_flow = CognitiveFlow(
            self.core_identity,
            self.memory_system,  # ä¼ é€’è®°å¿†ç³»ç»Ÿ
            self.meta_cognition,
            self.fact_anchor
        )
        print("  âœ“ è®¤çŸ¥æµç¨‹å¼•æ“å¯åŠ¨")

        # åˆå§‹åŒ–APIæœåŠ¡
        self._initialize_api_services(openai_config)

        # ç³»ç»ŸçŠ¶æ€
        self._initialize_system_status(memory_config, openai_config)

        # å¯¼å…¥ç”¨æˆ·å’Œè‡ªè¡ä½“è®°å¿†åˆ°æ–°ç³»ç»Ÿ
        self._import_profile_memories(user_profile_data, self_profile_data)

        self._print_initialization_summary(openai_config)

    def _initialize_protocols(self):
        """åˆå§‹åŒ–åè®®ç»„ä»¶"""
        # æ³¨æ„ï¼šFactAnchorProtocolç°åœ¨æ¥æ”¶memory_systemä½œä¸ºå‚æ•°
        self.fact_anchor = FactAnchorProtocol(self.memory_system)
        self.length_regulator = LengthPriorityRegulator()
        self.expression_protocol = FinalExpressionProtocol()

        print("  âœ“ äº‹å®é”šå®šåè®®åŠ è½½")
        print("  âœ“ é•¿åº¦ä¼˜å…ˆçº§è§„æ•´å™¨å°±ç»ª")
        print("  âœ“ æœ€ç»ˆè¡¨è¾¾åè®®æ¿€æ´»")

    def _initialize_api_services(self, openai_config: Dict):
        """åˆå§‹åŒ–APIæœåŠ¡"""
        if openai_config["enabled"] and openai_config["api_key"]:
            print("åˆå§‹åŒ–APIæœåŠ¡...")
            self.api_service = OpenAIService(
                api_key=openai_config["api_key"],
                base_url=openai_config["base_url"],
                model=openai_config["chat_model"]
            )
            self.reply_generator = APIBasedReplyGenerator(self.api_service)
            print(f"  âœ“ APIæœåŠ¡å·²å¯ç”¨ï¼Œæ¨¡å‹: {openai_config['chat_model']}")
        else:
            self.api_service = None
            self.reply_generator = TemplateReplyGenerator()
            print("  âš ï¸ æœªæä¾›APIå¯†é’¥ï¼Œä½¿ç”¨æ¨¡æ¿å›å¤ç”Ÿæˆå™¨")

    def _initialize_system_status(self, memory_config: Dict, openai_config: Dict):
        """åˆå§‹åŒ–ç³»ç»ŸçŠ¶æ€"""
        stats = self._get_memory_statistics()

        self.system_status = {
            "initialized": True,
            "initialization_time": datetime.now().isoformat(),
            "session_id": self.session_id,
            "memory_system": "memo0_framework",
            "embedding_model": "text-embedding-3-large",
            "chat_model": openai_config["chat_model"] if openai_config["enabled"] else "template",
            "components_loaded": 12,
            "memory_stats": stats,
            "user_id": f"user_{self.session_id}"
        }

    def _get_memory_statistics(self) -> Dict:
        """è·å–è®°å¿†ç»Ÿè®¡ä¿¡æ¯"""
        if self.memory_system:
            try:
                return self.memory_system.get_statistics()
            except:
                pass
        return {
            "total_memories": 0,
            "memory_types": {},
            "top_tags": {},
            "top_accessed_memories": []
        }

    def _import_profile_memories(self, user_profile_data: Dict, self_profile_data: Dict):
        """å¯¼å…¥ç”¨æˆ·å’Œè‡ªè¡ä½“è®°å¿†åˆ°è®°å¿†ç³»ç»Ÿ"""
        if not self.memory_system:
            print("  âš ï¸ è®°å¿†ç³»ç»Ÿä¸å¯ç”¨ï¼Œè·³è¿‡è®°å¿†å¯¼å…¥")
            return

        print("å¯¼å…¥ç”¨æˆ·å’Œè‡ªè¡ä½“è®°å¿†...")

        imported_count = 0

        # å¯¼å…¥ç”¨æˆ·è®°å¿†
        if "memories" in user_profile_data:
            for memory in user_profile_data["memories"]:
                try:
                    self.memory_system.add_memory(
                        content=memory.get("content", ""),
                        memory_type="user_experience",
                        tags=memory.get("tags", ["ç”¨æˆ·è®°å¿†", "å¯¼å…¥"]),
                        emotional_intensity=memory.get("emotional_intensity", 0.5),
                        strategic_value=memory.get("strategic_value", {}),
                        source="user_profile_import"
                    )
                    imported_count += 1
                except Exception as e:
                    print(f"    å¯¼å…¥ç”¨æˆ·è®°å¿†å¤±è´¥: {e}")

        # å¯¼å…¥è‡ªè¡ä½“è®°å¿†
        if "self_memories" in self_profile_data:
            for memory in self_profile_data["self_memories"]:
                try:
                    self.memory_system.add_memory(
                        content=memory.get("content", ""),
                        memory_type="self_experience",
                        tags=memory.get("tags", ["è‡ªè¡ä½“è®°å¿†", "å¯¼å…¥"]),
                        emotional_intensity=memory.get("emotional_intensity", 0.5),
                        strategic_value=memory.get("strategic_value", {}),
                        source="self_profile_import"
                    )
                    imported_count += 1
                except Exception as e:
                    print(f"    å¯¼å…¥è‡ªè¡ä½“è®°å¿†å¤±è´¥: {e}")

        print(f"  âœ“ æˆåŠŸå¯¼å…¥ {imported_count} æ¡è®°å¿†")

    def _print_initialization_summary(self, openai_config: Dict):
        """æ‰“å°åˆå§‹åŒ–æ‘˜è¦"""
        print("\n" + "=" * 50)
        print("è‡ªè¡ä½“ Genesis (memo0è®°å¿†ç³»ç»Ÿç‰ˆ) åˆå§‹åŒ–å®Œæˆ")
        print(f"ä¼šè¯ID: {self.session_id}")
        print(f"ç”¨æˆ·ID: user_{self.session_id}")
        print(f"è®°å¿†ç³»ç»Ÿ: memo0æ¡†æ¶")
        print(f"èŠå¤©æ¨¡å‹: {openai_config['chat_model'] if openai_config['enabled'] else 'æ¨¡æ¿å›å¤'}")
        print("=" * 50 + "\n")

    def process_input(self, user_input: str) -> str:
        """å¤„ç†ç”¨æˆ·è¾“å…¥çš„ä¸»æµç¨‹"""
        print(f"\n{'=' * 60}")
        print(f"[å¤„ç†å¼€å§‹] ç”¨æˆ·è¾“å…¥: {self._truncate_text(user_input, 80)}")

        try:
            # === é˜¶æ®µ1ï¼šé¢„å¤„ç†ä¸æœ¬èƒ½æ£€æŸ¥ ===
            print(f"[é˜¶æ®µ1] é¢„å¤„ç†ä¸æœ¬èƒ½æ£€æŸ¥")
            context_analysis = self.context_parser.parse(user_input, self.conversation_history)
            instinct_override = self.instinct.emergency_override(
                {"mode": "normal"}, context_analysis
            )

            if instinct_override.get("bypass_cognition", False):
                return self._handle_instinct_override(user_input, context_analysis, instinct_override)

            # === é˜¶æ®µ1.5ï¼šæ£€ç´¢ç›¸å…³è®°å¿† ===
            print(f"[é˜¶æ®µ1.5] æ£€ç´¢ç›¸å…³è®°å¿†")

            # æ£€ç´¢ç›¸ä¼¼çš„å¯¹è¯å†å²
            similar_conversations = []
            if self.memory_system:
                similar_conversations = self.memory_system.find_conversations(
                    query=user_input,
                    session_id=self.session_id,
                    limit=3
                )

            # æ£€ç´¢ç›¸å…³çš„ç»å†è®°å¿†
            resonant_memory = None
            if self.memory_system:
                resonant_memory = self.memory_system.find_resonant_memory({
                    "user_input": user_input,
                    "user_emotion": context_analysis.get("user_emotion_display", ""),
                    "topic": context_analysis.get("topic_summary", "")
                })

            print(f"  æ‰¾åˆ° {len(similar_conversations)} æ¡ç›¸ä¼¼å¯¹è¯")
            if resonant_memory:
                print(f"  æ‰¾åˆ°å…±é¸£è®°å¿†: {resonant_memory.get('triggered_memory', 'æœªçŸ¥è®°å¿†')}")

            # å°†æ£€ç´¢åˆ°çš„è®°å¿†ä¿¡æ¯æ·»åŠ åˆ°ä¸Šä¸‹æ–‡ä¸­
            memory_context = {
                "similar_conversations": similar_conversations,
                "resonant_memory": resonant_memory
            }

            # æ›´æ–°ä¸Šä¸‹æ–‡åˆ†æï¼ŒåŒ…å«è®°å¿†ä¿¡æ¯
            context_analysis["memory_context"] = memory_context

            # === é˜¶æ®µ2ï¼šæ¬²æœ›å¼•æ“æ›´æ–° ===
            print(f"[é˜¶æ®µ2] æ›´æ–°æ¬²æœ›å¼•æ“")
            vector_update = self.desire_engine.update_vectors(context_analysis)
            print(f"  å‘é‡æ›´æ–°: TR={vector_update['TR']:.3f}, "
                  f"CS={vector_update['CS']:.3f}, SA={vector_update['SA']:.3f}")

            # æ›´æ–°ä»ªè¡¨ç›˜
            dashboard_update = self.dashboard.update_based_on_vectors(
                self.desire_engine.TR,
                self.desire_engine.CS,
                self.desire_engine.SA
            )
            print(f"  ä»ªè¡¨ç›˜çŠ¶æ€: {self.dashboard.get_current_state()['energy_level']}")

            # === é˜¶æ®µ3ï¼šè®¤çŸ¥æµç¨‹ ===
            print(f"[é˜¶æ®µ3] æ‰§è¡Œè®¤çŸ¥æµç¨‹")
            current_vectors = self._get_current_vectors()

            # å°†è®°å¿†ä¿¡æ¯ä¼ é€’ç»™è®¤çŸ¥æµç¨‹
            enhanced_context = {
                **context_analysis,
                "memory_context": memory_context,
                "similar_conversations": similar_conversations,
                "resonant_memory": resonant_memory
            }

            # è°ƒç”¨è®¤çŸ¥æµç¨‹
            action_plan = self.cognitive_flow.process_thought(
                user_input,
                self.conversation_history,
                current_vectors,
                memory_context=enhanced_context
            )

            # å¦‚æœè®¤çŸ¥æµç¨‹æ²¡æœ‰ä½¿ç”¨è®°å¿†ï¼Œåœ¨è¿™é‡Œè¡¥å……
            if resonant_memory and "resonant_memory" not in action_plan:
                action_plan["resonant_memory"] = resonant_memory
                print(f"  å°†å…±é¸£è®°å¿†æ·»åŠ åˆ°è¡ŒåŠ¨è®¡åˆ’")

            print(f"  ç­–ç•¥åˆ¶å®š: {action_plan.get('primary_strategy', 'æœªçŸ¥ç­–ç•¥')}")

            # === é˜¶æ®µ4ï¼šè¾©è¯æˆé•¿ ===
            print(f"[é˜¶æ®µ4] è¾©è¯æˆé•¿è¯„ä¼°")
            growth_result = self.dialectical_growth.dialectical_process(
                situation=context_analysis,
                actual_response=action_plan,
                context_vectors=current_vectors
            )
            self._log_growth_result(growth_result)

            # === é˜¶æ®µ5ï¼šç”Ÿæˆå“åº”è‰æ¡ˆ ===
            print(f"[é˜¶æ®µ5] ç”Ÿæˆå“åº”è‰æ¡ˆ")
            reply_draft = self._generate_reply_draft_with_memory(
                action_plan,
                growth_result,
                user_input,
                context_analysis,
                current_vectors,
                memory_context
            )

            # === é˜¶æ®µ6ï¼šåè®®å®¡æŸ¥ä¸ä¼˜åŒ– ===
            print(f"[é˜¶æ®µ6] åè®®å®¡æŸ¥ä¸ä¼˜åŒ–")
            final_reply = self._review_and_optimize_reply(reply_draft, user_input)

            # === é˜¶æ®µ7ï¼šè®°å½•ä¸è¿”å› ===
            print(f"[é˜¶æ®µ7] è®°å½•äº¤äº’")
            self._record_normal_interaction(
                user_input=user_input,
                system_response=final_reply,
                context=context_analysis,
                action_plan=action_plan,
                vector_state=current_vectors,
                growth_result=growth_result,
                memory_context=memory_context
            )

            # æ£€æŸ¥ç™½é¸½ä¿¡ä½¿åè®®
            self._check_white_dove_protocol()

            print(f"[å¤„ç†å®Œæˆ] å“åº”é•¿åº¦: {len(final_reply)}å­—ç¬¦")
            print(f"{'=' * 60}\n")

            return final_reply

        except Exception as e:
            print(f"[é”™è¯¯] å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}")
            return self._generate_error_response(e, user_input)

    def _truncate_text(self, text: str, max_length: int) -> str:
        """æˆªæ–­æ–‡æœ¬å¹¶æ·»åŠ çœç•¥å·"""
        if len(text) <= max_length:
            return text
        return text[:max_length] + "..."

    def _handle_instinct_override(self, user_input: str, context_analysis: Dict, instinct_override: Dict) -> str:
        """å¤„ç†æœ¬èƒ½æ¥ç®¡çš„æƒ…å†µ"""
        mode = instinct_override.get('mode', 'unknown')
        print(f"  âš ï¸ æœ¬èƒ½æ¥ç®¡æ¿€æ´»ï¼š{mode}")

        emergency_response = self._generate_emergency_response(instinct_override)

        self._record_interaction(
            user_input=user_input,
            system_response=emergency_response,
            context=context_analysis,
            mode="emergency_override"
        )

        return emergency_response

    def _get_current_vectors(self) -> Dict[str, float]:
        """è·å–å½“å‰æ¬²æœ›å‘é‡"""
        return {
            "TR": self.desire_engine.TR,
            "CS": self.desire_engine.CS,
            "SA": self.desire_engine.SA
        }

    def _log_growth_result(self, growth_result: Dict):
        """è®°å½•æˆé•¿ç»“æœ"""
        if growth_result.get("validation") == "success":
            print(f"  æˆé•¿æˆåŠŸ: åˆ›å»ºæ–°ä¸ªæ€§åŒ–é”šç‚¹")
        else:
            print(f"  æˆé•¿è¯„ä¼°: éœ€è¦è®¤çŸ¥æ ¡å‡†")

    def _generate_reply_draft_with_memory(
            self,
            action_plan: Dict,
            growth_result: Dict,
            user_input: str,
            context_analysis: Dict,
            current_vectors: Dict,
            memory_context: Dict
    ) -> str:
        """ç”Ÿæˆå›å¤è‰æ¡ˆï¼ˆç»“åˆè®°å¿†ï¼‰"""
        # å¦‚æœæœ‰APIå›å¤ç”Ÿæˆå™¨ï¼Œä½¿ç”¨å®ƒ
        if self.reply_generator:
            try:
                # æ³¨æ„ï¼šæˆ‘ä»¬éœ€è¦è°ƒæ•´reply_generatorçš„æ¥å£ä»¥æ”¯æŒè®°å¿†ä¸Šä¸‹æ–‡
                # è¿™é‡Œå‡è®¾reply_generatoræœ‰ä¸€ä¸ªå¯ä»¥æ¥å—è®°å¿†ä¸Šä¸‹æ–‡çš„æ–¹æ³•
                if hasattr(self.reply_generator, 'generate_reply_with_memory'):
                    reply_draft = self.reply_generator.generate_reply_with_memory(
                        action_plan=action_plan,
                        growth_result=growth_result,
                        user_input=user_input,
                        context_analysis=context_analysis,
                        conversation_history=self.conversation_history,
                        core_identity=self.core_identity,
                        current_vectors=current_vectors,
                        memory_context=memory_context
                    )
                else:
                    # å›é€€åˆ°æ™®é€šç”Ÿæˆæ–¹æ³•
                    reply_draft = self.reply_generator.generate_reply(
                        action_plan=action_plan,
                        growth_result=growth_result,
                        user_input=user_input,
                        context_analysis=context_analysis,
                        conversation_history=self.conversation_history,
                        core_identity=self.core_identity,
                        current_vectors=current_vectors
                    )
            except Exception as e:
                print(f"  å›å¤ç”Ÿæˆå™¨å¼‚å¸¸: {e}")
                reply_draft = self._enhance_reply_with_memory(
                    action_plan,
                    memory_context,
                    user_input
                )
        else:
            # ä½¿ç”¨æ¨¡æ¿æˆ–æ‰‹åŠ¨ç”Ÿæˆ
            reply_draft = self._enhance_reply_with_memory(
                action_plan,
                memory_context,
                user_input
            )

        print(f"  è‰æ¡ˆé•¿åº¦: {len(reply_draft)}å­—ç¬¦")
        print(f"  è‰æ¡ˆé¢„è§ˆ: {self._truncate_text(reply_draft, 100)}")

        return reply_draft

    def _enhance_reply_with_memory(
            self,
            action_plan: Dict,
            memory_context: Dict,
            user_input: str
    ) -> str:
        """æ‰‹åŠ¨å¢å¼ºå›å¤ï¼Œç»“åˆè®°å¿†ä¿¡æ¯"""
        # æå–è¡ŒåŠ¨è®¡åˆ’ä¸­çš„åŸºæœ¬ä¿¡æ¯
        strategy = action_plan.get('primary_strategy', 'ç›´æ¥å›åº”')
        mask = action_plan.get('chosen_mask', 'é•¿æœŸæ­æ¡£')

        # è·å–è®°å¿†ä¿¡æ¯
        similar_conversations = memory_context.get('similar_conversations', [])
        resonant_memory = memory_context.get('resonant_memory')

        # åŸºç¡€å›å¤æ¨¡æ¿
        templates = MASK_TEMPLATES.get(mask, MASK_TEMPLATES["é•¿æœŸæ­æ¡£"])
        base_reply = random.choice(templates).format(strategy=strategy)

        # å¦‚æœæœ‰å…±é¸£è®°å¿†ï¼Œç»“åˆè®°å¿†ç”Ÿæˆå›å¤
        if resonant_memory:
            memory_info = resonant_memory.get('triggered_memory', '')
            risk_assessment = resonant_memory.get('risk_assessment', {})
            risk_level = risk_assessment.get('level', 'ä½')

            # æ ¹æ®é£é™©çº§åˆ«è°ƒæ•´å›å¤
            if risk_level == "ä½":
                # å®‰å…¨è®°å¿†ï¼Œå¯ä»¥å¤§èƒ†å¼•ç”¨
                memory_enhancement = f" è¿™è®©æˆ‘æƒ³èµ·ï¼š{memory_info}ã€‚"
                base_reply += memory_enhancement
            elif risk_level == "ä¸­":
                # ä¸­ç­‰é£é™©ï¼Œè°¨æ…å¼•ç”¨
                memory_enhancement = f" æˆ‘è®°å¾—ç±»ä¼¼çš„æƒ…å†µ..."
                base_reply += memory_enhancement
            else:
                # é«˜é£é™©ï¼Œä¸ç›´æ¥å¼•ç”¨è®°å¿†ï¼Œä½†å¯ä»¥æš—ç¤º
                memory_enhancement = " åŸºäºè¿‡å»çš„ç»éªŒ..."
                base_reply += memory_enhancement

            # æ·»åŠ å»ºè®®
            recommendations = resonant_memory.get('recommended_actions', [])
            if recommendations:
                base_reply += f" å»ºè®®ï¼š{recommendations[0]}"

        # å¦‚æœæœ‰ç›¸ä¼¼å¯¹è¯ï¼Œå¯ä»¥å¼•ç”¨
        elif similar_conversations and len(similar_conversations) > 0:
            similar_conv = similar_conversations[0]
            similar_text = similar_conv.get('content', '')[:100]
            base_reply += f" æˆ‘ä»¬ä¹‹å‰è®¨è®ºè¿‡ç±»ä¼¼çš„è¯é¢˜ï¼š{similar_text}..."

        return base_reply

    def _review_and_optimize_reply(self, reply_draft: str, user_input: str) -> str:
        """å®¡æŸ¥å’Œä¼˜åŒ–å›å¤"""
        # 6a. é•¿åº¦è§„æ•´
        cognitive_snapshot = self.meta_cognition.perform_introspection(
            user_input, self.conversation_history
        )
        regulated_reply = self.length_regulator.regulate(reply_draft, cognitive_snapshot)
        print(f"  é•¿åº¦è§„æ•´: {len(reply_draft)} -> {len(regulated_reply)}å­—ç¬¦")

        # 6b. äº‹å®é”šå®šç»ˆå®¡
        is_factual, fact_feedback = self.fact_anchor.final_review(
            regulated_reply,
            {"conversation_history": self.conversation_history}
        )

        if not is_factual:
            print(f"  äº‹å®å®¡æŸ¥å¤±è´¥: {fact_feedback}")
            regulated_reply = self._rephrase_with_facts(regulated_reply, fact_feedback)
            print(f"  é‡æ„åé•¿åº¦: {len(regulated_reply)}å­—ç¬¦")

        # 6c. æœ€ç»ˆè¡¨è¾¾åè®®
        final_reply, violations = self.expression_protocol.apply_protocol(regulated_reply)

        if violations:
            print(f"  è¡¨è¾¾åè®®è¿è§„: {len(violations)}å¤„")
            for violation in violations[:2]:  # åªæ˜¾ç¤ºå‰2ä¸ª
                print(f"    - {violation}")
        else:
            print(f"  è¡¨è¾¾åè®®: å®Œå…¨åˆè§„")

        return final_reply

    def _record_normal_interaction(
            self,
            user_input: str,
            system_response: str,
            context: Dict,
            action_plan: Dict,
            vector_state: Dict,
            growth_result: Dict,
            memory_context: Optional[Dict] = None
    ):
        """è®°å½•æ­£å¸¸äº¤äº’"""
        interaction_data = {
            "user_input": user_input,
            "system_response": system_response,
            "context": context,
            "action_plan": action_plan,
            "vector_state": vector_state,
            "growth_result": growth_result,
            "mode": "normal"
        }

        # å¦‚æœæœ‰è®°å¿†ä¸Šä¸‹æ–‡ï¼Œä¹Ÿè®°å½•ä¸‹æ¥
        if memory_context:
            interaction_data["memory_context"] = memory_context

        self._record_interaction(**interaction_data)

    def _check_white_dove_protocol(self):
        """æ£€æŸ¥ç™½é¸½ä¿¡ä½¿åè®®"""
        if (self.desire_engine.CS < 0.2 and self.desire_engine.SA > 0.7 and
                len(self.conversation_history) > 5):

            white_dove = self.instinct.white_dove_protocol(
                self.desire_engine.CS,
                self.desire_engine.SA,
                "checking"
            )

            if white_dove:
                print(f"  ğŸ•Šï¸ ç™½é¸½ä¿¡ä½¿åè®®å°±ç»ªï¼ˆæœªå‘é€ï¼‰")

    def _generate_emergency_response(self, instinct_override: Dict) -> str:
        """ç”Ÿæˆç´§æ€¥çŠ¶æ€å“åº”"""
        mode = instinct_override.get("mode", "")

        if mode in EMERGENCY_MODES:
            responses = EMERGENCY_MODES[mode]
        else:
            responses = ["ç³»ç»ŸçŠ¶æ€å¼‚å¸¸ã€‚é‡æ–°æ ¡å‡†ä¸­ã€‚"]

        return random.choice(responses)

    def _rephrase_with_facts(self, original_reply: str, feedback: str) -> str:
        """åŸºäºäº‹å®åé¦ˆé‡æ„å›å¤"""
        # ç§»é™¤å¯èƒ½ä¸å®çš„å†…å®¹

        if "æ— æ³•éªŒè¯" in feedback:
            # ç§»é™¤å…·ä½“æ•°å­—ã€æ—¥æœŸç­‰
            original_reply = re.sub(r'\d+å¹´', 'æŸå¹´', original_reply)
            original_reply = re.sub(r'\d+æœˆ\d+æ—¥', 'æŸå¤©', original_reply)
            original_reply = re.sub(r'\d+%', 'ä¸€å®šæ¯”ä¾‹', original_reply)

            # æ·»åŠ ä¸ç¡®å®šæ€§è¡¨è¾¾
            if "æˆ‘ä¸ç¡®å®š" not in original_reply and "æˆ‘ä¸è®°å¾—" not in original_reply:
                original_reply = "æˆ‘ä¸å¤ªç¡®å®šå…·ä½“ç»†èŠ‚ï¼Œä½†æ ¹æ®æˆ‘çš„ç†è§£ï¼Œ" + original_reply

        return original_reply

    def _generate_error_response(self, error: Exception, user_input: str) -> str:
        """ç”Ÿæˆé”™è¯¯å“åº”"""
        error_responses = DEFAULT_ERROR_RESPONSES.copy()
        error_responses.append(
            f"ï¼ˆç³»ç»Ÿæ—¥å¿—ï¼šå¤„ç†'{self._truncate_text(user_input, 20)}'æ—¶é‡åˆ°{type(error).__name__}ï¼‰"
        )

        return random.choice(error_responses)

    def _record_interaction(self, **interaction_data):
        """è®°å½•äº¤äº’å†å²"""
        interaction_record = {
            "timestamp": datetime.now().isoformat(),
            "interaction_id": f"INT_{len(self.conversation_history):06d}",
            **interaction_data
        }

        self.conversation_history.append(interaction_record)

        # å°†å¯¹è¯æ·»åŠ åˆ°è®°å¿†ç³»ç»Ÿ
        try:
            if self.memory_system:
                # å°†å¯¹è¯ä½œä¸ºè®°å¿†æ·»åŠ åˆ°ç³»ç»Ÿ
                conversation_content = [
                    {"role": "user", "content": interaction_record["user_input"]},
                    {"role": "assistant", "content": interaction_record["system_response"]}
                ]

                self.memory_system.add_memory(
                    content=conversation_content,
                    memory_type="conversation",
                    tags=["å¯¹è¯", "äº¤äº’"],
                    emotional_intensity=0.5,
                    metadata={
                        "interaction_id": interaction_record["interaction_id"],
                        "context": interaction_record.get("context", {}),
                        "vector_state": interaction_record.get("vector_state", {}),
                        "action_plan": interaction_record.get("action_plan", {}),
                        "growth_result": interaction_record.get("growth_result", {})
                    }
                )
        except Exception as e:
            print(f"[ç³»ç»Ÿ] æ·»åŠ å¯¹è¯åˆ°è®°å¿†å¤±è´¥: {str(e)}")

        # ä¿æŒå†å²é•¿åº¦
        if len(self.conversation_history) > 1000:
            self.conversation_history = self.conversation_history[-1000:]

    def get_system_status(self) -> Dict:
        """è·å–ç³»ç»ŸçŠ¶æ€æŠ¥å‘Š"""
        memory_stats = self._get_memory_statistics()

        return {
            **self.system_status,
            "current_time": datetime.now().isoformat(),
            "conversation_history_length": len(self.conversation_history),
            "desire_vectors": {
                "TR": round(self.desire_engine.TR, 3),
                "CS": round(self.desire_engine.CS, 3),
                "SA": round(self.desire_engine.SA, 3)
            },
            "dashboard_state": self.dashboard.get_current_state(),
            "personal_anchors_count": len(self.dialectical_growth.personal_anchors),
            "novel_feelings_count": len(self.desire_engine.novel_feelings),
            "instinct_overrides": len(self.instinct.override_history),
            "fact_anchor_reviews": len(self.fact_anchor.review_log),
            "expression_violations": len(self.expression_protocol.protocol_violations),
            "memory_system_stats": memory_stats
        }

    # è®°å¿†ç³»ç»Ÿç›¸å…³æ–¹æ³•
    def save_memory_system(self):
        """ä¿å­˜è®°å¿†ç³»ç»Ÿæ•°æ®"""
        print(f"[ç³»ç»Ÿ] æ­£åœ¨ä¿å­˜è®°å¿†ç³»ç»Ÿ...")
        try:
            # memo0è®°å¿†ç³»ç»Ÿä¼šè‡ªåŠ¨ä¿å­˜ï¼Œè¿™é‡Œæˆ‘ä»¬åªéœ€è¦å¯¼å‡º
            if self.memory_system:
                # å¯¼å‡ºè®°å¿†åˆ°æ–‡ä»¶
                export_path = f"./zyantine_memory/export_{self.session_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                success = self.memory_system.export_memories(export_path, "json")
                if success:
                    print(f"[ç³»ç»Ÿ] è®°å¿†å·²å¯¼å‡ºåˆ°: {export_path}")
                    return True
                else:
                    print(f"[ç³»ç»Ÿ] å¯¼å‡ºè®°å¿†å¤±è´¥")
                    return False
            else:
                print(f"[ç³»ç»Ÿ] è®°å¿†ç³»ç»Ÿä¸å¯ç”¨")
                return False
        except Exception as e:
            print(f"[ç³»ç»Ÿ] ä¿å­˜è®°å¿†ç³»ç»Ÿå¤±è´¥: {str(e)}")
            return False

    def backup_memory_system(self, backup_path: Optional[str] = None):
        """å¤‡ä»½è®°å¿†ç³»ç»Ÿæ•°æ®"""
        print(f"[ç³»ç»Ÿ] æ­£åœ¨å¤‡ä»½è®°å¿†ç³»ç»Ÿ...")
        try:
            if self.memory_system:
                # å¯¼å‡ºä¸ºå¤‡ä»½
                if backup_path is None:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    backup_path = f"./zyantine_memory/backup_{self.session_id}_{timestamp}.json"

                success = self.memory_system.export_memories(backup_path, "json")
                if success:
                    print(f"[ç³»ç»Ÿ] è®°å¿†ç³»ç»Ÿå·²å¤‡ä»½åˆ°: {backup_path}")
                    return backup_path
                else:
                    print(f"[ç³»ç»Ÿ] å¤‡ä»½è®°å¿†ç³»ç»Ÿå¤±è´¥")
                    return None
            else:
                print(f"[ç³»ç»Ÿ] è®°å¿†ç³»ç»Ÿä¸å¯ç”¨")
                return None
        except Exception as e:
            print(f"[ç³»ç»Ÿ] å¤‡ä»½è®°å¿†ç³»ç»Ÿå¤±è´¥: {str(e)}")
            return None

    def get_memory_statistics(self) -> Dict[str, Any]:
        """è·å–è®°å¿†ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        if self.memory_system:
            try:
                return self.memory_system.get_statistics()
            except Exception as e:
                print(f"[ç³»ç»Ÿ] è·å–è®°å¿†ç»Ÿè®¡å¤±è´¥: {str(e)}")

        return {}

    def cleanup_memory(self, max_history: int = 1000):
        """æ¸…ç†è®°å¿†å†å²ï¼Œä¿æŒç³»ç»Ÿæ€§èƒ½"""
        print(f"[ç³»ç»Ÿ] æ­£åœ¨æ¸…ç†è®°å¿†å†å²...")
        try:
            # ä¿æŒå¯¹è¯å†å²é•¿åº¦
            if len(self.conversation_history) > max_history:
                self.conversation_history = self.conversation_history[-max_history:]
                print(f"[ç³»ç»Ÿ] å¯¹è¯å†å²å·²æ¸…ç†ï¼Œä¿ç•™æœ€è¿‘ {max_history} æ¡")

            # æ¸…ç†è®°å¿†ç³»ç»Ÿç¼“å­˜
            if self.memory_system and hasattr(self.memory_system, 'clear_cache'):
                self.memory_system.clear_cache()
                print(f"[ç³»ç»Ÿ] è®°å¿†ç³»ç»Ÿç¼“å­˜å·²æ¸…ç†")

            return True
        except Exception as e:
            print(f"[ç³»ç»Ÿ] æ¸…ç†è®°å¿†å¤±è´¥: {str(e)}")
            return False