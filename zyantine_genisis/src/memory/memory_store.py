# ============ åŸºäºmemo0çš„ç®€åŒ–è®°å¿†ç³»ç»Ÿ ============
import os
import json
import hashlib
from datetime import datetime
from typing import Dict, List, Any, Optional, Union, Tuple
from dataclasses import dataclass, field
from enum import Enum

# Mem0æ¡†æ¶å¯¼å…¥
from mem0 import Memory
from openai import OpenAI

# ============ å¸¸é‡å®šä¹‰ ============
DEFAULT_BASE_URL = "https://openkey.cloud/v1"
DEFAULT_API_KEY = "sk-wiHpoarpNTHaep0t54852a32A75a4d6986108b3f6eF7B7B9"


# ============ ç±»å‹æšä¸¾ ============
class MemoryType(Enum):
    """è®°å¿†ç±»å‹æšä¸¾"""
    CONVERSATION = "conversation"
    EXPERIENCE = "experience"
    VECTOR_STATE = "vector_state"
    USER_PROFILE = "user_profile"
    SYSTEM_PROFILE = "system_profile"
    INSIGHT = "insight"


@dataclass
class MemoryMetadata:
    """è®°å¿†å…ƒæ•°æ®"""
    memory_id: str
    memory_type: str
    text: str
    tags: List[str] = field(default_factory=list)
    source: str = "unknown"
    emotional_intensity: float = 0.5
    strategic_value: Dict[str, Any] = field(default_factory=dict)
    linked_tool: Optional[str] = None
    access_count: int = 0
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    updated_at: str = field(default_factory=lambda: datetime.now().isoformat())
    session_id: str = "default"
    user_id: str = "default"


# ============ è®°å¿†ç³»ç»Ÿæ ¸å¿ƒç±» ============
class ZyantineMemorySystem:
    """åŸºäºmemo0çš„è‡ªè¡ä½“è®°å¿†ç³»ç»Ÿ"""

    def __init__(self,
                 base_url: str = DEFAULT_BASE_URL,
                 api_key: str = DEFAULT_API_KEY,
                 user_id: str = "default",
                 session_id: str = "default"):
        """
        åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ

        Args:
            base_url: OpenAI APIåŸºç¡€URL
            api_key: APIå¯†é’¥
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID
        """
        self.base_url = base_url
        self.api_key = api_key
        self.user_id = user_id
        self.session_id = session_id

        # åˆå§‹åŒ–memo0è®°å¿†ç³»ç»Ÿ
        self.memory = self._initialize_memo0()

        # è¯­ä¹‰è®°å¿†åœ°å›¾
        self.semantic_memory_map: Dict[str, Dict] = {}
        self.strategic_tags: List[str] = []

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_memories": 0,
            "by_type": {},
            "access_counts": {},
            "tags_distribution": {}
        }

        print(f"[è®°å¿†ç³»ç»Ÿ] åˆå§‹åŒ–å®Œæˆï¼Œç”¨æˆ·ID: {user_id}ï¼Œä¼šè¯ID: {session_id}")

    def _initialize_memo0(self) -> Memory:
        """åˆå§‹åŒ–memo0æ¡†æ¶"""
        config = {
            "vector_store": {
                "provider": "milvus",
                "config": {
                    "collection_name": "zyantine_memories",
                    "url": "http://localhost:19530",
                    "token": "",
                }
            },
            "llm": {
                "provider": "openai",
                "config": {
                    "openai_base_url": self.base_url,
                    "api_key": self.api_key
                }
            },
            "embedder": {
                "provider": "openai",
                "config": {
                    "model": "text-embedding-3-large",
                    "openai_base_url": self.base_url,
                    "api_key": self.api_key
                }
            }
        }

        return Memory.from_config(config)

    # ============ è®°å¿†CRUDæ“ä½œ ============

    def add_memory(self,
                   content: Union[str, List[Dict]],
                   memory_type: str = "conversation",
                   metadata: Optional[Dict] = None,
                   tags: Optional[List[str]] = None,
                   emotional_intensity: float = 0.5,
                   strategic_value: Optional[Dict] = None,
                   linked_tool: Optional[str] = None) -> str:
        """
        æ·»åŠ è®°å¿†

        Args:
            content: è®°å¿†å†…å®¹ï¼ˆå­—ç¬¦ä¸²æˆ–å¯¹è¯åˆ—è¡¨ï¼‰
            memory_type: è®°å¿†ç±»å‹
            metadata: é™„åŠ å…ƒæ•°æ®
            tags: æ ‡ç­¾åˆ—è¡¨
            emotional_intensity: æƒ…æ„Ÿå¼ºåº¦ (0-1)
            strategic_value: æˆ˜ç•¥ä»·å€¼è¯„ä¼°
            linked_tool: å…³è”çš„è®¤çŸ¥å·¥å…·

        Returns:
            è®°å¿†ID
        """
        # ç”Ÿæˆè®°å¿†ID
        if isinstance(content, str):
            content_str = content
        else:
            content_str = json.dumps(content, ensure_ascii=False)

        memory_id = self._generate_memory_id(content_str, memory_type)

        # å‡†å¤‡å®Œæ•´å†…å®¹
        if isinstance(content, list):
            # å¯¹è¯æ ¼å¼
            full_content = content
        else:
            # æ–‡æœ¬æ ¼å¼
            full_content = [{"role": "user", "content": content}]

        # å‡†å¤‡å…ƒæ•°æ®
        memory_metadata = self._prepare_metadata(
            memory_id=memory_id,
            memory_type=memory_type,
            content=content_str,
            metadata=metadata or {},
            tags=tags or [],
            emotional_intensity=emotional_intensity,
            strategic_value=strategic_value or {},
            linked_tool=linked_tool
        )

        # æ·»åŠ åˆ°memo0
        self.memory.add(
            full_content,
            user_id=self.user_id,
            metadata=memory_metadata
        )

        # æ›´æ–°è¯­ä¹‰è®°å¿†åœ°å›¾
        self._update_semantic_memory(memory_id, memory_metadata)

        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self._update_stats(memory_type, tags or [])

        print(f"[è®°å¿†ç³»ç»Ÿ] æ·»åŠ è®°å¿†æˆåŠŸï¼ŒID: {memory_id}ï¼Œç±»å‹: {memory_type}")
        return memory_id

    def _generate_memory_id(self, content: str, memory_type: str) -> str:
        """ç”Ÿæˆè®°å¿†ID"""
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        content_hash = hashlib.md5(content.encode()).hexdigest()[:8]
        return f"{memory_type}_{timestamp}_{content_hash}"

    def _prepare_metadata(self,
                          memory_id: str,
                          memory_type: str,
                          content: str,
                          metadata: Dict,
                          tags: List[str],
                          emotional_intensity: float,
                          strategic_value: Dict,
                          linked_tool: Optional[str]) -> Dict:
        """å‡†å¤‡å…ƒæ•°æ®"""
        base_metadata = {
            "memory_id": memory_id,
            "memory_type": memory_type,
            "session_id": self.session_id,
            "created_at": datetime.now().isoformat(),
            "tags": tags,
            "emotional_intensity": emotional_intensity,
            "strategic_value": strategic_value,
            "linked_tool": linked_tool,
            "source": "zyantine_system",
            "content_length": len(content)
        }

        # åˆå¹¶ç”¨æˆ·æä¾›çš„å…ƒæ•°æ®
        base_metadata.update(metadata)

        return base_metadata

    def _update_semantic_memory(self, memory_id: str, metadata: Dict):
        """æ›´æ–°è¯­ä¹‰è®°å¿†åœ°å›¾"""
        self.semantic_memory_map[memory_id] = {
            "metadata": metadata,
            "access_count": 0,
            "last_accessed": None,
            "strategic_score": metadata.get("strategic_value", {}).get("score", 0)
        }

    def _update_stats(self, memory_type: str, tags: List[str]):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        self.stats["total_memories"] += 1

        # æŒ‰ç±»å‹ç»Ÿè®¡
        if memory_type not in self.stats["by_type"]:
            self.stats["by_type"][memory_type] = 0
        self.stats["by_type"][memory_type] += 1

        # æ ‡ç­¾åˆ†å¸ƒ
        for tag in tags:
            if tag not in self.stats["tags_distribution"]:
                self.stats["tags_distribution"][tag] = 0
            self.stats["tags_distribution"][tag] += 1

        # æ›´æ–°æˆ˜ç•¥æ ‡ç­¾
        for tag in tags:
            if tag not in self.strategic_tags:
                self.strategic_tags.append(tag)

    # ============ è®°å¿†æ£€ç´¢ ============

    def search_memories(self,
                        query: str,
                        memory_type: Optional[str] = None,
                        tags: Optional[List[str]] = None,
                        limit: int = 5,
                        similarity_threshold: float = 0.7,
                        rerank: bool = True) -> List[Dict]:
        """
        æœç´¢è®°å¿†

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            memory_type: è®°å¿†ç±»å‹è¿‡æ»¤
            tags: æ ‡ç­¾è¿‡æ»¤
            limit: è¿”å›æ•°é‡é™åˆ¶
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            rerank: æ˜¯å¦é‡æ–°æ’åº

        Returns:
            è®°å¿†ç»“æœåˆ—è¡¨
        """
        # æ„å»ºå…ƒæ•°æ®è¿‡æ»¤å™¨
        metadata_filter = {}
        if memory_type:
            metadata_filter["memory_type"] = memory_type
        if tags:
            metadata_filter["tags"] = tags

        # æ‰§è¡Œæœç´¢
        search_results = self.memory.search(
            query,
            user_id=self.user_id,
            limit=limit,
            rerank=rerank
        )

        # å¤„ç†ç»“æœ
        processed_results = []
        for hit in search_results.get("results", []):
            memory_data = hit.get("memory", {})
            metadata = hit.get("metadata", {})
            score = hit.get("score", 0)

            # åº”ç”¨ç›¸ä¼¼åº¦é˜ˆå€¼
            if score < similarity_threshold:
                continue

            # æ›´æ–°è®¿é—®ç»Ÿè®¡
            memory_id = metadata.get("memory_id")
            if memory_id and memory_id in self.semantic_memory_map:
                self.semantic_memory_map[memory_id]["access_count"] += 1
                self.semantic_memory_map[memory_id]["last_accessed"] = datetime.now().isoformat()

                # æ›´æ–°å…¨å±€è®¿é—®ç»Ÿè®¡
                if memory_id not in self.stats["access_counts"]:
                    self.stats["access_counts"][memory_id] = 0
                self.stats["access_counts"][memory_id] += 1

            # æ„å»ºç»“æœ
            result = {
                "memory_id": memory_id,
                "content": self._extract_content_from_memory(memory_data),
                "metadata": metadata,
                "similarity_score": score,
                "memory_type": metadata.get("memory_type"),
                "tags": metadata.get("tags", []),
                "emotional_intensity": metadata.get("emotional_intensity", 0.5),
                "strategic_value": metadata.get("strategic_value", {}),
                "linked_tool": metadata.get("linked_tool"),
                "created_at": metadata.get("created_at"),
                "access_count": self.semantic_memory_map.get(memory_id, {}).get("access_count", 0)
            }

            processed_results.append(result)

        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        processed_results.sort(key=lambda x: x["similarity_score"], reverse=True)

        return processed_results[:limit]

    def _extract_content_from_memory(self, memory_data: Any) -> str:
        """ä»è®°å¿†æ•°æ®ä¸­æå–å†…å®¹"""
        if isinstance(memory_data, list):
            # å¯¹è¯æ ¼å¼
            content_parts = []
            for msg in memory_data:
                if isinstance(msg, dict):
                    role = msg.get("role", "")
                    content = msg.get("content", "")
                    content_parts.append(f"{role}: {content}")
            return "\n".join(content_parts)
        elif isinstance(memory_data, str):
            return memory_data
        else:
            return str(memory_data)

    def find_conversations(self,
                           query: str,
                           session_id: Optional[str] = None,
                           limit: int = 5) -> List[Dict]:
        """
        æŸ¥æ‰¾ç›¸å…³å¯¹è¯

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            session_id: ä¼šè¯IDè¿‡æ»¤
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            å¯¹è¯ç»“æœåˆ—è¡¨
        """
        metadata_filter = {"memory_type": MemoryType.CONVERSATION.value}
        if session_id:
            metadata_filter["session_id"] = session_id
        else:
            metadata_filter["session_id"] = self.session_id

        return self.search_memories(
            query=query,
            memory_type=MemoryType.CONVERSATION.value,
            limit=limit
        )

    def find_experiences(self,
                         context: Dict,
                         limit: int = 3) -> List[Dict]:
        """
        æŸ¥æ‰¾ç›¸å…³ç»å†è®°å¿†

        Args:
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            ç»å†è®°å¿†åˆ—è¡¨
        """
        # æ„å»ºæŸ¥è¯¢
        query_parts = []
        if "user_input" in context:
            query_parts.append(context["user_input"])
        if "user_emotion" in context:
            query_parts.append(f"æƒ…ç»ª {context['user_emotion']}")
        if "topic" in context:
            query_parts.append(f"è¯é¢˜ {context['topic']}")

        query = " ".join(query_parts)

        return self.search_memories(
            query=query,
            memory_type=MemoryType.EXPERIENCE.value,
            limit=limit
        )

    # ============ è®°å¿†ç®¡ç† ============

    def get_memory(self, memory_id: str) -> Optional[Dict]:
        """
        è·å–ç‰¹å®šè®°å¿†

        Args:
            memory_id: è®°å¿†ID

        Returns:
            è®°å¿†ä¿¡æ¯æˆ–None
        """
        # é¦–å…ˆå°è¯•ä»è¯­ä¹‰è®°å¿†åœ°å›¾è·å–
        if memory_id in self.semantic_memory_map:
            # é€šè¿‡æœç´¢æ‰¾åˆ°å…·ä½“è®°å¿†
            search_results = self.search_memories(
                query=memory_id,  # ä½¿ç”¨IDä½œä¸ºæŸ¥è¯¢
                limit=1
            )

            if search_results:
                memory_info = search_results[0]

                # æ›´æ–°è®¿é—®ç»Ÿè®¡
                self.semantic_memory_map[memory_id]["access_count"] += 1
                self.semantic_memory_map[memory_id]["last_accessed"] = datetime.now().isoformat()

                return memory_info

        return None

    def update_memory(self,
                      memory_id: str,
                      new_content: Optional[str] = None,
                      new_tags: Optional[List[str]] = None,
                      new_metadata: Optional[Dict] = None) -> bool:
        """
        æ›´æ–°è®°å¿†

        Args:
            memory_id: è®°å¿†ID
            new_content: æ–°å†…å®¹
            new_tags: æ–°æ ‡ç­¾
            new_metadata: æ–°å…ƒæ•°æ®

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        # è·å–ç°æœ‰è®°å¿†
        memory_info = self.get_memory(memory_id)
        if not memory_info:
            return False

        # æ„å»ºæ›´æ–°å†…å®¹
        current_metadata = memory_info.get("metadata", {})

        if new_tags:
            current_metadata["tags"] = new_tags

        if new_metadata:
            current_metadata.update(new_metadata)

        # æ ‡è®°ä¸ºæ›´æ–°
        current_metadata["updated_at"] = datetime.now().isoformat()

        # å¦‚æœéœ€è¦æ›´æ–°å†…å®¹ï¼Œåˆ›å»ºæ–°è®°å¿†å¹¶æ ‡è®°æ—§è®°å¿†
        if new_content:
            # åˆ›å»ºæ–°è®°å¿†
            self.add_memory(
                content=new_content,
                memory_type=current_metadata.get("memory_type", "conversation"),
                metadata=current_metadata,
                tags=current_metadata.get("tags", []),
                emotional_intensity=current_metadata.get("emotional_intensity", 0.5),
                strategic_value=current_metadata.get("strategic_value", {}),
                linked_tool=current_metadata.get("linked_tool")
            )

            # æ ‡è®°æ—§è®°å¿†ä¸ºå·²æ›´æ–°
            if memory_id in self.semantic_memory_map:
                self.semantic_memory_map[memory_id]["status"] = "updated"

        return True

    def delete_memory(self, memory_id: str) -> bool:
        """
        åˆ é™¤è®°å¿†

        Args:
            memory_id: è®°å¿†ID

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        # memo0æ¡†æ¶ç›®å‰æ²¡æœ‰ç›´æ¥çš„åˆ é™¤API
        # æˆ‘ä»¬å¯ä»¥é€šè¿‡æ ‡è®°ä¸ºåˆ é™¤æ¥å®ç°
        if memory_id in self.semantic_memory_map:
            self.semantic_memory_map[memory_id]["status"] = "deleted"
            self.semantic_memory_map[memory_id]["deleted_at"] = datetime.now().isoformat()

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.stats["total_memories"] = max(0, self.stats["total_memories"] - 1)

            print(f"[è®°å¿†ç³»ç»Ÿ] è®°å¿†æ ‡è®°ä¸ºåˆ é™¤: {memory_id}")
            return True

        return False

    # ============ æ‰¹é‡æ“ä½œ ============

    def add_conversation_batch(self, conversations: List[Dict]) -> List[str]:
        """
        æ‰¹é‡æ·»åŠ å¯¹è¯

        Args:
            conversations: å¯¹è¯åˆ—è¡¨

        Returns:
            è®°å¿†IDåˆ—è¡¨
        """
        memory_ids = []

        for conv in conversations:
            memory_id = self.add_memory(
                content=conv,
                memory_type=MemoryType.CONVERSATION.value,
                tags=["å¯¹è¯", "æ‰¹é‡å¯¼å…¥"],
                emotional_intensity=conv.get("emotional_intensity", 0.5)
            )
            memory_ids.append(memory_id)

        return memory_ids

    def import_user_profile(self, profile_data: Dict) -> List[str]:
        """
        å¯¼å…¥ç”¨æˆ·æ¡£æ¡ˆæ•°æ®

        Args:
            profile_data: ç”¨æˆ·æ¡£æ¡ˆæ•°æ®

        Returns:
            è®°å¿†IDåˆ—è¡¨
        """
        memory_ids = []

        # å¯¼å…¥ç”¨æˆ·è®°å¿†
        if "memories" in profile_data:
            for memory in profile_data["memories"]:
                memory_id = self.add_memory(
                    content=memory.get("content", ""),
                    memory_type=MemoryType.EXPERIENCE.value,
                    tags=memory.get("tags", ["ç”¨æˆ·è®°å¿†"]),
                    emotional_intensity=memory.get("emotional_intensity", 0.5),
                    strategic_value=memory.get("strategic_value", {}),
                    source="user_profile_import"
                )
                memory_ids.append(memory_id)

        # å¯¼å…¥ç”¨æˆ·ç‰¹å¾
        if "personality_traits" in profile_data:
            traits_text = json.dumps(profile_data["personality_traits"], ensure_ascii=False)
            memory_id = self.add_memory(
                content=f"ç”¨æˆ·æ€§æ ¼ç‰¹å¾: {traits_text}",
                memory_type=MemoryType.USER_PROFILE.value,
                tags=["æ€§æ ¼ç‰¹å¾", "ç”¨æˆ·æ¡£æ¡ˆ"],
                source="user_profile_import"
            )
            memory_ids.append(memory_id)

        return memory_ids

    # ============ ç»Ÿè®¡ä¸åˆ†æ ============

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        # è®¡ç®—æœ€å¸¸ç”¨çš„æ ‡ç­¾
        top_tags = sorted(
            self.stats["tags_distribution"].items(),
            key=lambda x: x[1],
            reverse=True
        )[:10]

        # è®¡ç®—æœ€å¸¸è®¿é—®çš„è®°å¿†
        top_accessed = sorted(
            self.semantic_memory_map.items(),
            key=lambda x: x[1].get("access_count", 0),
            reverse=True
        )[:5]

        top_accessed_formatted = []
        for mem_id, mem_data in top_accessed:
            top_accessed_formatted.append({
                "memory_id": mem_id,
                "access_count": mem_data.get("access_count", 0),
                "last_accessed": mem_data.get("last_accessed"),
                "strategic_score": mem_data.get("strategic_score", 0)
            })

        return {
            "total_memories": self.stats["total_memories"],
            "memory_types": self.stats["by_type"],
            "top_tags": dict(top_tags),
            "top_accessed_memories": top_accessed_formatted,
            "strategic_tags_count": len(self.strategic_tags),
            "user_id": self.user_id,
            "session_id": self.session_id,
            "semantic_map_size": len(self.semantic_memory_map)
        }

    def analyze_memory_patterns(self) -> Dict[str, Any]:
        """
        åˆ†æè®°å¿†æ¨¡å¼

        Returns:
            æ¨¡å¼åˆ†æç»“æœ
        """
        # æŒ‰ç±»å‹åˆ†æ
        type_analysis = {}
        for mem_id, mem_data in self.semantic_memory_map.items():
            mem_type = mem_data.get("metadata", {}).get("memory_type")
            if mem_type not in type_analysis:
                type_analysis[mem_type] = {
                    "count": 0,
                    "total_access": 0,
                    "avg_emotional_intensity": 0
                }

            analysis = type_analysis[mem_type]
            analysis["count"] += 1
            analysis["total_access"] += mem_data.get("access_count", 0)

            # æƒ…æ„Ÿå¼ºåº¦ç´¯è®¡
            emotional_intensity = mem_data.get("metadata", {}).get("emotional_intensity", 0.5)
            if "emotional_intensity_sum" not in analysis:
                analysis["emotional_intensity_sum"] = 0
                analysis["emotional_intensity_count"] = 0

            analysis["emotional_intensity_sum"] += emotional_intensity
            analysis["emotional_intensity_count"] += 1

        # è®¡ç®—å¹³å‡å€¼
        for mem_type, analysis in type_analysis.items():
            if analysis["count"] > 0:
                analysis["avg_access"] = analysis["total_access"] / analysis["count"]
            if analysis.get("emotional_intensity_count", 0) > 0:
                analysis["avg_emotional_intensity"] = (
                        analysis["emotional_intensity_sum"] / analysis["emotional_intensity_count"]
                )

            # ç§»é™¤ä¸´æ—¶å­—æ®µ
            analysis.pop("emotional_intensity_sum", None)
            analysis.pop("emotional_intensity_count", None)

        return {
            "type_analysis": type_analysis,
            "strategic_tags": self.strategic_tags,
            "high_value_memories": self._get_high_value_memories()
        }

    def _get_high_value_memories(self) -> List[Dict]:
        """è·å–é«˜ä»·å€¼è®°å¿†"""
        high_value_memories = []

        for mem_id, mem_data in self.semantic_memory_map.items():
            strategic_score = mem_data.get("strategic_score", 0)
            access_count = mem_data.get("access_count", 0)

            # é«˜ä»·å€¼æ ‡å‡†ï¼šæˆ˜ç•¥åˆ†æ•°é«˜æˆ–è®¿é—®æ¬¡æ•°å¤š
            if strategic_score > 2 or access_count > 3:
                high_value_memories.append({
                    "memory_id": mem_id,
                    "strategic_score": strategic_score,
                    "access_count": access_count,
                    "tags": mem_data.get("metadata", {}).get("tags", []),
                    "memory_type": mem_data.get("metadata", {}).get("memory_type")
                })

        # æŒ‰æˆ˜ç•¥åˆ†æ•°æ’åº
        high_value_memories.sort(key=lambda x: x["strategic_score"], reverse=True)
        return high_value_memories[:10]

    # ============ å¯¼å‡ºä¸å¤‡ä»½ ============

    def export_memories(self, file_path: str, format_type: str = "json") -> bool:
        """
        å¯¼å‡ºè®°å¿†

        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            format_type: å¯¼å‡ºæ ¼å¼

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            export_data = {
                "metadata": {
                    "export_time": datetime.now().isoformat(),
                    "user_id": self.user_id,
                    "session_id": self.session_id,
                    "total_memories": self.stats["total_memories"]
                },
                "semantic_memory_map": self.semantic_memory_map,
                "statistics": self.stats,
                "strategic_tags": self.strategic_tags
            }

            with open(file_path, 'w', encoding='utf-8') as f:
                if format_type == "json":
                    json.dump(export_data, f, ensure_ascii=False, indent=2)
                else:
                    # å…¶ä»–æ ¼å¼å¯æ‰©å±•
                    f.write(str(export_data))

            print(f"[è®°å¿†ç³»ç»Ÿ] è®°å¿†å¯¼å‡ºæˆåŠŸ: {file_path}")
            return True

        except Exception as e:
            print(f"[è®°å¿†ç³»ç»Ÿ] è®°å¿†å¯¼å‡ºå¤±è´¥: {e}")
            return False

    # ============ è®°å¿†ç‚¼é‡‘æœ¯å¼•æ“ ============

    def find_resonant_memory(self, context: Dict) -> Optional[Dict]:
        """
        å¯»æ‰¾å…±é¸£è®°å¿†

        Args:
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯

        Returns:
            å…±é¸£è®°å¿†åŒ…
        """
        # æ„å»ºæŸ¥è¯¢
        query_text = self._build_resonance_query(context)

        if not query_text:
            return None

        # æœç´¢ç›¸å…³ç»å†è®°å¿†
        similar_experiences = self.find_experiences(context, limit=3)

        if not similar_experiences:
            # å¦‚æœæ²¡æœ‰ç›´æ¥ç»å†ï¼Œæœç´¢ç›¸å…³å¯¹è¯
            similar_conversations = self.find_conversations(
                query=query_text,
                limit=2
            )

            if similar_conversations:
                best_match = similar_conversations[0]
            else:
                return None
        else:
            best_match = similar_experiences[0]

        # æ„å»ºæˆ˜æœ¯ä¿¡æ¯åŒ…
        tactical_package = self._build_tactical_package(best_match, context)

        return tactical_package

    def _build_resonance_query(self, context: Dict) -> str:
        """æ„å»ºå…±é¸£æŸ¥è¯¢"""
        query_parts = []

        if "user_input" in context:
            query_parts.append(context["user_input"])

        if "user_emotion" in context:
            query_parts.append(f"æƒ…ç»ª: {context['user_emotion']}")

        if "topic" in context:
            query_parts.append(f"è¯é¢˜: {context['topic']}")

        return " ".join(query_parts) if query_parts else ""

    def _build_tactical_package(self, memory_match: Dict, context: Dict) -> Dict:
        """æ„å»ºæˆ˜æœ¯ä¿¡æ¯åŒ…"""
        metadata = memory_match.get("metadata", {})

        package = {
            "triggered_memory": memory_match.get("content", "æœªçŸ¥è®°å¿†"),
            "memory_id": memory_match.get("memory_id"),
            "relevance_score": memory_match.get("similarity_score", 0),
            "source": metadata.get("source", "unknown"),
            "tags": metadata.get("tags", []),
            "strategic_value": metadata.get("strategic_value", {}),
            "linked_tool": metadata.get("linked_tool"),
            "emotional_intensity": metadata.get("emotional_intensity", 0.5),
            "risk_assessment": self._assess_memory_risk(metadata),
            "recommended_actions": self._generate_recommendations(metadata, context),
            "timestamp": datetime.now().isoformat(),
            "retrieval_method": "memo0_vector_search"
        }

        return package

    def _assess_memory_risk(self, metadata: Dict) -> Dict[str, Any]:
        """è¯„ä¼°è®°å¿†é£é™©"""
        risk_score = 0
        high_risk_factors = []

        # é«˜é£é™©æ ‡ç­¾
        high_risk_tags = ["åˆ›ä¼¤", "èƒŒå›", "å¤±è´¥", "ç—›è‹¦"]
        tags = metadata.get("tags", [])

        for tag in tags:
            if tag in high_risk_tags:
                risk_score += 3
                high_risk_factors.append(tag)

        # æƒ…æ„Ÿå¼ºåº¦å½±å“
        emotional_intensity = metadata.get("emotional_intensity", 0.5)
        if emotional_intensity > 0.8:
            risk_score += 2

        # ç¡®å®šé£é™©çº§åˆ«
        if risk_score >= 5:
            level = "é«˜"
        elif risk_score >= 3:
            level = "ä¸­"
        elif risk_score >= 1:
            level = "ä½"
        else:
            level = "æä½"

        return {
            "level": level,
            "score": risk_score,
            "high_risk_factors": high_risk_factors
        }

    def _generate_recommendations(self, metadata: Dict, context: Dict) -> List[str]:
        """ç”Ÿæˆä½¿ç”¨å»ºè®®"""
        recommendations = []
        tags = metadata.get("tags", [])

        if "æˆå°±" in tags or "æˆåŠŸ" in tags:
            recommendations.append("å¯å®‰å…¨æåŠä»¥æ¿€æ´»ç§¯ææƒ…ç»ª")

        if "åˆ›ä¼¤" in tags or "ç—›è‹¦" in tags:
            recommendations.append("é«˜é£é™©åŒºåŸŸï¼Œè°¨æ…ä½¿ç”¨")

        if "å­¦ä¹ " in tags or "æˆé•¿" in tags:
            recommendations.append("é€‚åˆç”¨äºæ¿€åŠ±åœºæ™¯")

        return recommendations if recommendations else ["å¸¸è§„è®°å¿†ï¼Œå¯çµæ´»ä½¿ç”¨"]

    # ============ å·¥å…·æ–¹æ³• ============

    def clear_cache(self):
        """æ¸…ç†ç¼“å­˜"""
        # é‡ç½®è¯­ä¹‰è®°å¿†åœ°å›¾
        self.semantic_memory_map.clear()
        self.strategic_tags.clear()

        # é‡ç½®ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_memories": 0,
            "by_type": {},
            "access_counts": {},
            "tags_distribution": {}
        }

        print("[è®°å¿†ç³»ç»Ÿ] ç¼“å­˜å·²æ¸…ç†")

    def test_connection(self) -> bool:
        """æµ‹è¯•è¿æ¥"""
        try:
            # æµ‹è¯•æ·»åŠ å’Œæœç´¢
            test_id = self.add_memory(
                content="è¿æ¥æµ‹è¯•",
                memory_type="test",
                tags=["æµ‹è¯•"]
            )

            results = self.search_memories("è¿æ¥æµ‹è¯•", limit=1)

            if results and len(results) > 0:
                print("[è®°å¿†ç³»ç»Ÿ] è¿æ¥æµ‹è¯•æˆåŠŸ")
                return True
            else:
                print("[è®°å¿†ç³»ç»Ÿ] è¿æ¥æµ‹è¯•å¤±è´¥")
                return False

        except Exception as e:
            print(f"[è®°å¿†ç³»ç»Ÿ] è¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
            return False


# ============ ä½¿ç”¨ç¤ºä¾‹ ============
if __name__ == "__main__":
    # 1. åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ
    memory_system = ZyantineMemorySystem(
        user_id="demo-user",
        session_id="session-001"
    )

    # 2. æµ‹è¯•è¿æ¥
    if memory_system.test_connection():
        print("âœ… è®°å¿†ç³»ç»Ÿè¿æ¥æˆåŠŸ")
    else:
        print("âŒ è®°å¿†ç³»ç»Ÿè¿æ¥å¤±è´¥")

    # 3. æ·»åŠ å¯¹è¯è®°å¿†
    conversation = [
        {"role": "user", "content": "ä½ å¥½ï¼Œæˆ‘å«å°æ˜"},
        {"role": "assistant", "content": "ä½ å¥½å°æ˜ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ï¼"}
    ]

    memory_id = memory_system.add_memory(
        content=conversation,
        memory_type=MemoryType.CONVERSATION.value,
        tags=["åˆæ¬¡è§é¢", "è‡ªæˆ‘ä»‹ç»"],
        emotional_intensity=0.7
    )

    print(f"âœ… å¯¹è¯è®°å¿†æ·»åŠ æˆåŠŸï¼ŒID: {memory_id}")

    # 4. æ·»åŠ ç»å†è®°å¿†
    experience_id = memory_system.add_memory(
        content="æˆ‘ç¬¬ä¸€æ¬¡å­¦ä¹ ç¼–ç¨‹æ˜¯åœ¨å¤§å­¦æ—¶æœŸï¼Œå½“æ—¶å¯¹Pythonäº§ç”Ÿäº†æµ“åšå…´è¶£",
        memory_type=MemoryType.EXPERIENCE.value,
        tags=["å­¦ä¹ ", "ç¼–ç¨‹", "Python", "å¤§å­¦"],
        emotional_intensity=0.8,
        strategic_value={"level": "é«˜", "score": 4}
    )

    print(f"âœ… ç»å†è®°å¿†æ·»åŠ æˆåŠŸï¼ŒID: {experience_id}")

    # 5. æœç´¢è®°å¿†
    search_results = memory_system.search_memories(
        query="ç”¨æˆ·å«ä»€ä¹ˆåå­—",
        memory_type=MemoryType.CONVERSATION.value,
        limit=3
    )

    print(f"ğŸ” æœç´¢ç»“æœ ({len(search_results)} æ¡):")
    for result in search_results:
        print(f"  - {result['memory_id']}: {result['content'][:50]}... (ç›¸ä¼¼åº¦: {result['similarity_score']:.3f})")

    # 6. è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = memory_system.get_statistics()
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯: æ€»è®°å¿†æ•° {stats['total_memories']}")

    # 7. å¯»æ‰¾å…±é¸£è®°å¿†
    context = {
        "user_input": "æˆ‘å¯¹ç¼–ç¨‹å¾ˆæ„Ÿå…´è¶£",
        "user_emotion": "å…´å¥‹",
        "topic": "å­¦ä¹ ç¼–ç¨‹"
    }

    resonant_memory = memory_system.find_resonant_memory(context)
    if resonant_memory:
        print(f"ğŸ¯ æ‰¾åˆ°å…±é¸£è®°å¿†: {resonant_memory['triggered_memory'][:50]}...")

    # 8. å¯¼å‡ºè®°å¿†
    memory_system.export_memories("memory_export.json")