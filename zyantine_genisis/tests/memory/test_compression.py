"""
æµ‹è¯•è®°å¿†å‹ç¼©å’Œå½’æ¡£åŠŸèƒ½
"""
import time
from datetime import datetime, timedelta
from memory.memory_manager import (
    MemoryManager,
    MemoryType,
    MemoryPriority,
    MemoryRecord
)


def test_compression_and_archiving():
    """æµ‹è¯•å‹ç¼©å’Œå½’æ¡£åŠŸèƒ½"""
    print("="*60)
    print("æµ‹è¯•è®°å¿†å‹ç¼©å’Œå½’æ¡£åŠŸèƒ½")
    print("="*60)
    
    manager = MemoryManager()
    
    # æ·»åŠ ä¸€äº›æµ‹è¯•è®°å¿†
    print("\næ·»åŠ æµ‹è¯•è®°å¿†...")
    test_memories = [
        ("ç”¨æˆ·å–œæ¬¢ç¼–ç¨‹å’Œäººå·¥æ™ºèƒ½", MemoryType.USER_PROFILE, ["ç”¨æˆ·", "ç¼–ç¨‹"], MemoryPriority.HIGH),
        ("æ˜¨å¤©è®¨è®ºäº†æœºå™¨å­¦ä¹ ç®—æ³•", MemoryType.CONVERSATION, ["æœºå™¨å­¦ä¹ ", "è®¨è®º"], MemoryPriority.MEDIUM),
        ("ç³»ç»Ÿå¯åŠ¨æˆåŠŸ", MemoryType.SYSTEM_EVENT, ["ç³»ç»Ÿ", "å¯åŠ¨"], MemoryPriority.LOW),
        ("Pythonæ˜¯ä¸€ç§æµè¡Œçš„ç¼–ç¨‹è¯­è¨€", MemoryType.KNOWLEDGE, ["Python", "ç¼–ç¨‹"], MemoryPriority.HIGH),
        ("ç”¨æˆ·æœ€è¿‘åœ¨ç ”ç©¶æ·±åº¦å­¦ä¹ ", MemoryType.USER_PROFILE, ["ç”¨æˆ·", "æ·±åº¦å­¦ä¹ "], MemoryPriority.HIGH),
        ("ä»Šå¤©å¤©æ°”å¾ˆå¥½", MemoryType.CONVERSATION, ["å¤©æ°”"], MemoryPriority.LOW),
        ("ç³»ç»Ÿé…ç½®å·²å®Œæˆ", MemoryType.SYSTEM_EVENT, ["ç³»ç»Ÿ", "é…ç½®"], MemoryPriority.MEDIUM),
        ("JavaScriptæ˜¯Webå¼€å‘çš„æ ¸å¿ƒ", MemoryType.KNOWLEDGE, ["JavaScript", "Web"], MemoryPriority.MEDIUM),
    ]
    
    memory_ids = []
    for content, mtype, tags, priority in test_memories:
        memory_id = manager.add_memory(
            content=content,
            memory_type=mtype,
            tags=tags,
            priority=priority
        )
        memory_ids.append(memory_id)
        print(f"  âœ“ æ·»åŠ è®°å¿†: {content[:20]}... (ä¼˜å…ˆçº§: {priority.value})")
    
    time.sleep(1)
    
    # æµ‹è¯•1: è·å–å‹ç¼©ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "="*60)
    print("æµ‹è¯•1: è·å–å‹ç¼©ç»Ÿè®¡ä¿¡æ¯")
    print("="*60)
    
    stats = manager.get_compression_stats()
    print(f"  æ€»å‹ç¼©æ•°: {stats['total_compressed']}")
    print(f"  æ€»å½’æ¡£æ•°: {stats['total_archived']}")
    print(f"  æ€»èŠ‚çœç©ºé—´: {stats['total_size_saved']} bytes")
    print(f"  å‹ç¼©ç‡: {stats['compression_ratio']:.2%}")
    print(f"  ç¼“å­˜ä¸­å‹ç¼©æ•°: {stats['compressed_in_cache']}")
    print(f"  ç¼“å­˜ä¸­å½’æ¡£æ•°: {stats['archived_in_cache']}")
    print("  âœ“ å‹ç¼©ç»Ÿè®¡ä¿¡æ¯è·å–æˆåŠŸ")
    
    # æµ‹è¯•2: è·å–å‹ç¼©å’Œå½’æ¡£é˜ˆå€¼é…ç½®
    print("\n" + "="*60)
    print("æµ‹è¯•2: è·å–å‹ç¼©å’Œå½’æ¡£é˜ˆå€¼é…ç½®")
    print("="*60)
    
    thresholds = manager.get_compression_thresholds()
    print("  å‹ç¼©é˜ˆå€¼:")
    print(f"    - å†…å®¹å¤§å°: {thresholds['compression']['size_bytes']} bytes")
    print(f"    - å¹´é¾„: {thresholds['compression']['age_hours']} å°æ—¶")
    print(f"    - è®¿é—®æ¬¡æ•°: {thresholds['compression']['access_count']}")
    print(f"    - ä¼˜å…ˆçº§: {[p.value for p in thresholds['compression']['priority']]}")
    print("  å½’æ¡£é˜ˆå€¼:")
    print(f"    - å¹´é¾„: {thresholds['archive']['age_hours']} å°æ—¶")
    print(f"    - ä¼˜å…ˆçº§: {[p.value for p in thresholds['archive']['priority']]}")
    print(f"    - æœªè®¿é—®æ—¶é—´: {thresholds['archive']['no_access_hours']} å°æ—¶")
    print("  âœ“ é˜ˆå€¼é…ç½®è·å–æˆåŠŸ")
    
    # æµ‹è¯•3: æ›´æ–°å‹ç¼©é˜ˆå€¼
    print("\n" + "="*60)
    print("æµ‹è¯•3: æ›´æ–°å‹ç¼©é˜ˆå€¼")
    print("="*60)
    
    manager.update_compression_thresholds(size_bytes=5000, age_hours=360)
    
    updated_thresholds = manager.get_compression_thresholds()
    if updated_thresholds['compression']['size_bytes'] == 5000 and updated_thresholds['compression']['age_hours'] == 360:
        print("  âœ“ å‹ç¼©é˜ˆå€¼æ›´æ–°æˆåŠŸ")
        print(f"    å†…å®¹å¤§å°é˜ˆå€¼å·²æ›´æ–°ä¸º: 5000 bytes")
        print(f"    å¹´é¾„é˜ˆå€¼å·²æ›´æ–°ä¸º: 360 å°æ—¶")
    else:
        print("  âœ— å‹ç¼©é˜ˆå€¼æ›´æ–°å¤±è´¥")
        return False
    
    # æµ‹è¯•4: æ›´æ–°å½’æ¡£é˜ˆå€¼
    print("\n" + "="*60)
    print("æµ‹è¯•4: æ›´æ–°å½’æ¡£é˜ˆå€¼")
    print("="*60)
    
    manager.update_archive_thresholds(age_hours=1080, no_access_hours=720)
    
    updated_thresholds = manager.get_compression_thresholds()
    if updated_thresholds['archive']['age_hours'] == 1080 and updated_thresholds['archive']['no_access_hours'] == 720:
        print("  âœ“ å½’æ¡£é˜ˆå€¼æ›´æ–°æˆåŠŸ")
        print(f"    å¹´é¾„é˜ˆå€¼å·²æ›´æ–°ä¸º: 1080 å°æ—¶")
        print(f"    æœªè®¿é—®æ—¶é—´é˜ˆå€¼å·²æ›´æ–°ä¸º: 720 å°æ—¶")
    else:
        print("  âœ— å½’æ¡£é˜ˆå€¼æ›´æ–°å¤±è´¥")
        return False
    
    # æµ‹è¯•5: å‹ç¼©å•ä¸ªè®°å¿†
    print("\n" + "="*60)
    print("æµ‹è¯•5: å‹ç¼©å•ä¸ªè®°å¿†")
    print("="*60)
    
    # åˆ›å»ºä¸€ä¸ªè¾ƒå¤§çš„è®°å¿†å†…å®¹
    large_content = "è¿™æ˜¯ä¸€ä¸ªè¾ƒå¤§çš„è®°å¿†å†…å®¹ã€‚" * 500
    large_memory_id = manager.add_memory(
        content=large_content,
        memory_type=MemoryType.KNOWLEDGE,
        tags=["æµ‹è¯•", "å¤§å†…å®¹"],
        priority=MemoryPriority.LOW
    )
    
    # å‹ç¼©è®°å¿†
    compressed_record = manager.compress_memory(large_memory_id)
    if compressed_record and compressed_record.metadata.get("compressed", False):
        print("  âœ“ è®°å¿†å‹ç¼©æˆåŠŸ")
        print(f"    åŸå§‹å¤§å°: {compressed_record.metadata.get('original_size', 0)} bytes")
        print(f"    å‹ç¼©åå¤§å°: {compressed_record.size_bytes} bytes")
    else:
        print("  âœ— è®°å¿†å‹ç¼©å¤±è´¥")
        return False
    
    # æµ‹è¯•6: å½’æ¡£å•ä¸ªè®°å¿†
    print("\n" + "="*60)
    print("æµ‹è¯•6: å½’æ¡£å•ä¸ªè®°å¿†")
    print("="*60)
    
    # åˆ›å»ºä¸€ä¸ªè¾ƒæ—§çš„è®°å¿†
    old_content = "è¿™æ˜¯ä¸€ä¸ªè¾ƒæ—§çš„è®°å¿†å†…å®¹ã€‚"
    old_memory_id = manager.add_memory(
        content=old_content,
        memory_type=MemoryType.CONVERSATION,
        tags=["æµ‹è¯•", "æ—§å†…å®¹"],
        priority=MemoryPriority.LOW
    )
    
    # æ‰‹åŠ¨è®¾ç½®è®°å¿†ä¸ºè¾ƒæ—§
    record = manager.cache.get(old_memory_id)
    if record:
        record.created_at = datetime.now() - timedelta(hours=2500)
        manager.cache.set(old_memory_id, record, record.version)
    
    # å½’æ¡£è®°å¿†
    archived_record = manager.archive_memory(old_memory_id)
    if archived_record and archived_record.metadata.get("archived", False):
        print("  âœ“ è®°å¿†å½’æ¡£æˆåŠŸ")
        print(f"    ä¼˜å…ˆçº§: {archived_record.priority.value}")
        print(f"    å·²å‹ç¼©: {archived_record.metadata.get('compressed', False)}")
    else:
        print("  âœ— è®°å¿†å½’æ¡£å¤±è´¥")
        return False
    
    # æµ‹è¯•7: è§£å‹ç¼©è®°å¿†
    print("\n" + "="*60)
    print("æµ‹è¯•7: è§£å‹ç¼©è®°å¿†")
    print("="*60)
    
    decompressed_record = manager.decompress_memory(large_memory_id)
    if decompressed_record and not decompressed_record.metadata.get("compressed", False):
        print("  âœ“ è®°å¿†è§£å‹æˆåŠŸ")
        print(f"    å¤§å°: {decompressed_record.size_bytes} bytes")
    else:
        print("  âœ— è®°å¿†è§£å‹å¤±è´¥")
        return False
    
    # æµ‹è¯•8: æ‰¹é‡å‹ç¼©è®°å¿†
    print("\n" + "="*60)
    print("æµ‹è¯•8: æ‰¹é‡å‹ç¼©è®°å¿†")
    print("="*60)
    
    # æ·»åŠ æ›´å¤šæµ‹è¯•è®°å¿†
    for i in range(5):
        content = f"æ‰¹é‡æµ‹è¯•è®°å¿† {i}ã€‚" * 200
        memory_id = manager.add_memory(
            content=content,
            memory_type=MemoryType.KNOWLEDGE,
            tags=["æ‰¹é‡æµ‹è¯•"],
            priority=MemoryPriority.LOW
        )
        memory_ids.append(memory_id)
    
    # æ‰¹é‡å‹ç¼©
    compress_result = manager.batch_compress_memories()
    print(f"  æ‰¹é‡å‹ç¼©ç»“æœ:")
    print(f"    å‹ç¼©æ•°é‡: {compress_result['compressed']}")
    print(f"    è·³è¿‡æ•°é‡: {compress_result['skipped']}")
    print(f"    æ€»æ•°é‡: {compress_result['total']}")
    print("  âœ“ æ‰¹é‡å‹ç¼©æˆåŠŸ")
    
    # æµ‹è¯•9: æ‰¹é‡å½’æ¡£è®°å¿†
    print("\n" + "="*60)
    print("æµ‹è¯•9: æ‰¹é‡å½’æ¡£è®°å¿†")
    print("="*60)
    
    # æ·»åŠ æ›´å¤šè¾ƒæ—§çš„æµ‹è¯•è®°å¿†
    for i in range(5):
        content = f"æ‰¹é‡å½’æ¡£æµ‹è¯•è®°å¿† {i}ã€‚"
        memory_id = manager.add_memory(
            content=content,
            memory_type=MemoryType.CONVERSATION,
            tags=["æ‰¹é‡å½’æ¡£"],
            priority=MemoryPriority.LOW
        )
        
        # è®¾ç½®ä¸ºè¾ƒæ—§
        record = manager.cache.get(memory_id)
        if record:
            record.created_at = datetime.now() - timedelta(hours=2500)
            manager.cache.set(memory_id, record, record.version)
        
        memory_ids.append(memory_id)
    
    # æ‰¹é‡å½’æ¡£
    archive_result = manager.batch_archive_memories()
    print(f"  æ‰¹é‡å½’æ¡£ç»“æœ:")
    print(f"    å½’æ¡£æ•°é‡: {archive_result['archived']}")
    print(f"    è·³è¿‡æ•°é‡: {archive_result['skipped']}")
    print(f"    æ€»æ•°é‡: {archive_result['total']}")
    print("  âœ“ æ‰¹é‡å½’æ¡£æˆåŠŸ")
    
    # æµ‹è¯•10: è‡ªåŠ¨å‹ç¼©å’Œå½’æ¡£
    print("\n" + "="*60)
    print("æµ‹è¯•10: è‡ªåŠ¨å‹ç¼©å’Œå½’æ¡£")
    print("="*60)
    
    auto_result = manager.auto_compress_and_archive()
    print(f"  è‡ªåŠ¨å‹ç¼©å’Œå½’æ¡£ç»“æœ:")
    print(f"    å‹ç¼©æ•°é‡: {auto_result['compressed']}")
    print(f"    å½’æ¡£æ•°é‡: {auto_result['archived']}")
    print("  âœ“ è‡ªåŠ¨å‹ç¼©å’Œå½’æ¡£æˆåŠŸ")
    
    # æµ‹è¯•11: æœç´¢å‹ç¼©çš„è®°å¿†
    print("\n" + "="*60)
    print("æµ‹è¯•11: æœç´¢å‹ç¼©çš„è®°å¿†")
    print("="*60)
    
    # æœç´¢åŒ…å«"æ‰¹é‡æµ‹è¯•"çš„è®°å¿†
    search_results = manager.search_memories(
        query="æ‰¹é‡æµ‹è¯•",
        limit=5
    )
    
    print(f"  æ‰¾åˆ° {len(search_results)} æ¡è®°å¿†")
    for i, record in enumerate(search_results[:3], 1):
        content_preview = str(record.content)[:50] if record.content else "None"
        print(f"    {i}. {content_preview}... (å‹ç¼©: {record.metadata.get('compressed', False)})")
    print("  âœ“ æœç´¢å‹ç¼©è®°å¿†æˆåŠŸ")
    
    # æµ‹è¯•12: è·å–æœ€ç»ˆå‹ç¼©ç»Ÿè®¡
    print("\n" + "="*60)
    print("æµ‹è¯•12: è·å–æœ€ç»ˆå‹ç¼©ç»Ÿè®¡")
    print("="*60)
    
    final_stats = manager.get_compression_stats()
    print(f"  æ€»å‹ç¼©æ•°: {final_stats['total_compressed']}")
    print(f"  æ€»å½’æ¡£æ•°: {final_stats['total_archived']}")
    print(f"  æ€»èŠ‚çœç©ºé—´: {final_stats['total_size_saved']} bytes")
    print(f"  å‹ç¼©ç‡: {final_stats['compression_ratio']:.2%}")
    print(f"  ç¼“å­˜ä¸­å‹ç¼©æ•°: {final_stats['compressed_in_cache']}")
    print(f"  ç¼“å­˜ä¸­å½’æ¡£æ•°: {final_stats['archived_in_cache']}")
    print("  âœ“ æœ€ç»ˆå‹ç¼©ç»Ÿè®¡è·å–æˆåŠŸ")
    
    print("\n" + "="*60)
    print("ğŸ‰ æ‰€æœ‰å‹ç¼©å’Œå½’æ¡£æµ‹è¯•é€šè¿‡ï¼")
    print("="*60)
    
    return True


if __name__ == "__main__":
    try:
        success = test_compression_and_archiving()
        if success:
            print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡")
        else:
            print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
