2026-01-06 11:08:26 - llm_service_openai - WARNING - 初始连接测试失败: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead. (request id: 2026010611082569391751773207827)", 'type': 'invalid_request_error', 'param': '', 'code': None}}
2026-01-06 11:08:26 - llm_service_openai - INFO - openai服务初始化完成，模型: gpt-5-nano-2025-08-07
2026-01-06 11:09:04 - llm_service_openai - ERROR - 生成回复失败: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead. (request id: 2026010611090382443552378578033)", 'type': 'invalid_request_error', 'param': '', 'code': None}}
2026-01-06 11:10:06 - llm_service_openai - INFO - 正在关闭openai服务...
2026-01-06 11:10:06 - llm_service_openai - INFO - openai服务已关闭
2026-01-06 11:10:06 - llm_service_openai - INFO - 正在关闭openai服务...
2026-01-06 11:10:06 - llm_service_openai - INFO - openai服务已关闭
2026-01-06 20:44:57 - llm_service_openai - WARNING - 初始连接测试失败: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead. (request id: 2026010620445677945945941579575)", 'type': 'invalid_request_error', 'param': '', 'code': None}}
2026-01-06 20:44:57 - llm_service_openai - INFO - openai服务初始化完成，模型: gpt-5-nano-2025-08-07
2026-01-06 20:45:39 - llm_service_openai - ERROR - 生成回复失败: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead. (request id: 2026010620453886830275777912443)", 'type': 'invalid_request_error', 'param': '', 'code': None}}
2026-01-06 20:47:42 - llm_service_openai - WARNING - 初始连接测试失败: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead. (request id: 2026010620474140616400796481674)", 'type': 'invalid_request_error', 'param': '', 'code': None}}
2026-01-06 20:47:42 - llm_service_openai - INFO - openai服务初始化完成，模型: gpt-5-nano-2025-08-07
2026-01-06 20:47:55 - llm_service_openai - ERROR - 生成回复失败: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead. (request id: 2026010620475457490406497966202)", 'type': 'invalid_request_error', 'param': '', 'code': None}}
2026-01-06 22:02:55 - llm_service_openai - WARNING - 初始连接测试失败: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead. (request id: 2026010622025529837944664228478)", 'type': 'invalid_request_error', 'param': '', 'code': None}}
2026-01-06 22:02:55 - llm_service_openai - INFO - openai服务初始化完成，模型: gpt-5-nano-2025-08-07
2026-01-06 22:03:06 - llm_service_openai - ERROR - 生成回复失败: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead. (request id: 2026010622030579575797218172749)", 'type': 'invalid_request_error', 'param': '', 'code': None}}
2026-01-06 22:03:19 - llm_service_openai - INFO - 正在关闭openai服务...
2026-01-06 22:03:19 - llm_service_openai - INFO - openai服务已关闭
2026-01-06 22:03:19 - llm_service_openai - INFO - 正在关闭openai服务...
2026-01-06 22:03:19 - llm_service_openai - INFO - openai服务已关闭
2026-01-06 23:05:57 - llm_service_openai - WARNING - 初始连接测试失败: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead. (request id: 2026010623055654359508296778902)", 'type': 'invalid_request_error', 'param': '', 'code': None}}
2026-01-06 23:05:57 - llm_service_openai - INFO - openai服务初始化完成，模型: gpt-5-nano-2025-08-07
2026-01-06 23:06:09 - llm_service_openai - ERROR - 生成回复失败: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead. (request id: 2026010623060847319639782367006)", 'type': 'invalid_request_error', 'param': '', 'code': None}}
2026-01-08 09:52:37 - llm_service_openai - ERROR - 生成回复失败: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead. (request id: 2026010809513253151176317144451)", 'type': 'invalid_request_error', 'param': '', 'code': None}}
